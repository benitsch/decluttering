{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Bidirectional, TimeDistributed,Conv1D, MaxPooling1D, Input, concatenate\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.layers import GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import os\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(maxlen = 50, max_features = 4590, embed_size =32):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, embed_size, input_length=maxlen))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(GRU(8,dropout=0.3, activation='softmax'))\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def CNN(maxlen=50, max_features=4590, embed_size=32):\n",
    "    # Inputs\n",
    "    comment_seq = Input(shape=[maxlen], name='x_seq')\n",
    "\n",
    "    # Embeddings layers\n",
    "    emb_comment = Embedding(max_features, embed_size)(comment_seq)\n",
    "\n",
    "    # conv layers\n",
    "    convs = []\n",
    "#     filter_sizes = [2, 3, 4, 5]\n",
    "    filter_sizes = [2, 3]\n",
    "\n",
    "    for fsz in filter_sizes:\n",
    "        l_conv = Conv1D(filters=10, kernel_size=fsz, activation='relu')(emb_comment)\n",
    "        l_pool = MaxPooling1D(maxlen - fsz + 1)(l_conv)\n",
    "        l_pool = Flatten()(l_pool)\n",
    "        convs.append(l_pool)\n",
    "    merge = concatenate(convs, axis=1)\n",
    "\n",
    "    out = Dropout(0.5)(merge)\n",
    "    output = Dense(16, activation='relu')(out)\n",
    "\n",
    "    output = Dense(units=1, activation='sigmoid')(output)\n",
    "\n",
    "    model = Model([comment_seq], output)\n",
    "    #     adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050, 41)\n",
      "(1050,)\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x_seq (InputLayer)              (None, 41)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 41, 32)       416         x_seq[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 40, 10)       650         embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 39, 10)       970         embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 1, 10)        0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 1, 10)        0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 10)           0           max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 10)           0           max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 20)           0           flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 20)           0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 16)           336         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 1)            17          dense_26[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,389\n",
      "Trainable params: 2,389\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## read Data\n",
    "input_file = \"csv/training_data.csv\"\n",
    "dataframe = pd.read_csv(input_file, na_filter = False)\n",
    "trainingData = []\n",
    "label = []\n",
    "for i,d in dataframe.iterrows():\n",
    "    trainingData.append(d[\"data\"])\n",
    "    label.append(d[\"label\"])\n",
    "\n",
    "\n",
    "trainingData_rohe = numpy.array(trainingData)\n",
    "trainingData_new = []\n",
    "for td in trainingData_rohe:\n",
    "    feature = (td.replace(\"[\",\"\").replace(\"]\",\"\").split(','))\n",
    "    results = list(map(int, feature))\n",
    "    trainingData_new.append(results)\n",
    "# print(trainingData_new)\n",
    "label = numpy.array(label)\n",
    "trainingData_new = numpy.array(trainingData_new)\n",
    "print(trainingData_new.shape)\n",
    "print(label.shape)\n",
    "## build model\n",
    "def read_vocabulary(file_name):\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        return iterable_to_dict(f.readlines())\n",
    "\n",
    "def iterable_to_dict(arr):\n",
    "    return dict((x.strip(), (i)) for (i, x) in enumerate(arr))\n",
    "\n",
    "vocabFile = \"csv/vocab.txt\"\n",
    "word_vocabulary = read_vocabulary(vocabFile)\n",
    "CNN_model = CNN(len(trainingData_new[0]),len(vocabFile))\n",
    "CNN_model.summary()\n",
    "#model compile\n",
    "CNN_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 787 samples, validate on 263 samples\n",
      "Epoch 1/10\n",
      "787/787 [==============================] - 4s 5ms/step - loss: 2314254666311335424.0000 - accuracy: 0.6277 - val_loss: 991270453283256832.0000 - val_accuracy: 0.3764\n",
      "Epoch 2/10\n",
      "787/787 [==============================] - 2s 3ms/step - loss: 1511.8976 - accuracy: 0.7471 - val_loss: 991270387552293504.0000 - val_accuracy: 0.3764\n",
      "Epoch 3/10\n",
      "787/787 [==============================] - 2s 3ms/step - loss: 1511.8976 - accuracy: 0.7471 - val_loss: 991270387552293504.0000 - val_accuracy: 0.3764\n",
      "Epoch 4/10\n",
      "787/787 [==============================] - 2s 3ms/step - loss: 1511.8976 - accuracy: 0.7471 - val_loss: 991270387552293504.0000 - val_accuracy: 0.3764\n",
      "Epoch 5/10\n",
      "787/787 [==============================] - 2s 3ms/step - loss: 1511.8977 - accuracy: 0.7471 - val_loss: 991270387552293504.0000 - val_accuracy: 0.3764\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "total num: 1050\n",
      "469\n"
     ]
    }
   ],
   "source": [
    "## training \n",
    "batch_size = 5\n",
    "epochs = 10\n",
    "es = EarlyStopping(monitor='val_loss', patience=3)\n",
    "CNN_model.fit(trainingData_new, label,\n",
    "          validation_split=0.25,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[es],\n",
    "          shuffle=True)\n",
    "i = 0\n",
    "for f, b in zip(trainingData_new, label):\n",
    "    i += predict(f,b)\n",
    "print(\"total num:\",len(trainingData_new))\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(testData, truth):\n",
    "    test = numpy.reshape(testData,(1,testData.shape[0]))\n",
    "    pr = model.predict(test)\n",
    "    \n",
    "    if (pr >= 0.5 and truth == 1) or (pr< 0.5 and truth ==0):\n",
    "#         print(\"true\")\n",
    "        print(pr)\n",
    "        return 1\n",
    "    else:\n",
    "#         print(\"false\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, 41, 32)            416       \n",
      "_________________________________________________________________\n",
      "gru_13 (GRU)                 (None, 8)                 984       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,409\n",
      "Trainable params: 1,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 787 samples, validate on 263 samples\n",
      "Epoch 1/10\n",
      "787/787 [==============================] - 48s 60ms/step - loss: 0.5812 - accuracy: 0.7471 - val_loss: 0.7038 - val_accuracy: 0.6008\n",
      "Epoch 2/10\n",
      "787/787 [==============================] - 45s 58ms/step - loss: 0.5671 - accuracy: 0.7471 - val_loss: 0.7137 - val_accuracy: 0.6008\n",
      "Epoch 3/10\n",
      "787/787 [==============================] - 46s 58ms/step - loss: 0.5662 - accuracy: 0.7471 - val_loss: 0.7173 - val_accuracy: 0.6008\n",
      "Epoch 4/10\n",
      "787/787 [==============================] - 46s 58ms/step - loss: 0.5658 - accuracy: 0.7471 - val_loss: 0.7217 - val_accuracy: 0.6008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d26bbe1348>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(len(trainingData_new[0]),len(vocabFile))\n",
    "model.summary()\n",
    "#model compile\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "## training \n",
    "batch_size = 2\n",
    "epochs = 10\n",
    "es = EarlyStopping(monitor='val_loss', patience=3)\n",
    "model.fit(trainingData_new, label,\n",
    "          validation_split=0.25,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[es],\n",
    "          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "[[0.25598285]]\n",
      "total num: 1050\n",
      "746\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for f, b in zip(trainingData_new, label):\n",
    "    i += predict(f,b)\n",
    "print(\"total num:\",len(trainingData_new))\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
