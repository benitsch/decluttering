{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "import re\n",
    "def train_w2v(x):\n",
    "\n",
    "    model = Word2Vec(x, size =100, window = 6, min_count=0, workers=3)\n",
    "    \n",
    "    # save it as binary\n",
    "    model.save('model/w2v_model.pkl')\n",
    "    \n",
    "    print(model)\n",
    "    return model\n",
    "#     imdb_w2v = Word2Vec(size=n_dim,min_count=5,seed=1)\n",
    "#     imdb_w2v.bulid_voab(x)\n",
    "#     w2v_model = Word2Vec(min_count=20,\n",
    "#                      window=2,\n",
    "#                      size=300,\n",
    "#                      sample=6e-5, \n",
    "#                      alpha=0.03, \n",
    "#                      min_alpha=0.0007, \n",
    "#                      negative=20,\n",
    "#                      workers=cores-1)\n",
    "#     t = time()\n",
    "\n",
    "#     w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "\n",
    "#     imdb_w2v.train(x,total_examples=imdb_w2v.corpus_count,epochs=30)\n",
    "#     imdb_w2v.save('model/w2v_model.pkl')\n",
    "\n",
    "#     return imdb_w2v\n",
    "\n",
    "\n",
    "def load_w2v(x,n_dim,path):\n",
    "    if os.path.exists(path):\n",
    "        imdb_w2v = Word2Vec.load(path)\n",
    "    else:\n",
    "        imdb_w2v = train_w2v(x,n_dim=n_dim)\n",
    "    return w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tran_vecs(imdb_w2v,x,n_dim,padding_size=300):\n",
    "\tbatch_text = []\n",
    "\tfor text in x:\n",
    "\t\tmatrix = []\n",
    "\t\tfor i in range(padding_size):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tvec = imdb_w2v[text[i]]\n",
    "\t\t\t\tmatrix.append(vec)\n",
    "\t\t\texcept:\n",
    "\t\t\t\tmatrix.append([0]*n_dim)\n",
    "\t\tbatch_text.append(matrix)\n",
    "\treturn np.array(batch_text)\n",
    "delimiters = \"#\", \".\",\",\",\"<b>\",\"</b>\",\"-\",\":\",\"<br>\",\"_\",\"?\",\" \",\";\"\n",
    "def splitComment(string,delimiters = delimiters, maxsplit=0):\n",
    "## replace all web https to https\n",
    "    for l in string.split():\n",
    "        if l.startswith(\"https\"):\n",
    "            string = string.replace(l,\"https\")\n",
    "    ## split string by delimiters\n",
    "    regexPattern = '|'.join(map(re.escape, delimiters))\n",
    "    result =  re.split(regexPattern, string, maxsplit)\n",
    "    ## split string by uppercase\n",
    "    f = []\n",
    "    for r in result:\n",
    "        p =  re.sub(r'((?<=[a-z])[A-Z]|(?<!\\A)[A-Z](?=[a-z]))', r' \\1', r)\n",
    "#         print(p)\n",
    "        for q in p.split():\n",
    "            if q != \"\":\n",
    "                f.append(q)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#extract all words\n",
    "padding_size = 50\n",
    "path = \"csv/oneLineCode.csv\"\n",
    "dataframe = pd.read_csv(path, na_filter = False)\n",
    "s = \"\"\n",
    "for i,data in dataframe.iterrows():\n",
    "    d = splitComment(data[\"comment\"])\n",
    "    c = splitComment(data[\"code\"])\n",
    "    if d != []:\n",
    "        s +=  ' '.join(d) +\"\\n\"\n",
    "    if c != []:\n",
    "        s += ' '.join(c) +\"\\n\"\n",
    "with open(\"csv/allWords.txt\", 'w', encoding='utf-8') as text:\n",
    "    text.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150271"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = gensim.models.word2vec.Text8Corpus('csv/allWords.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=4532, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "model = train_w2v(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(model.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.22748257, -0.05292923, -0.04464341, -0.04136555,  0.22128715,\n",
       "        0.23957503,  0.00263121,  0.05862024,  0.07777222,  0.04933307,\n",
       "        0.34330004,  0.2514837 , -0.11439779,  0.02665494, -0.02235066,\n",
       "        0.00605818, -0.0524811 ,  0.2122897 , -0.08477834, -0.06084725,\n",
       "        0.04231981, -0.02952179,  0.25066966,  0.04827298, -0.25940174,\n",
       "        0.02796778,  0.16331182, -0.02548233,  0.11079974, -0.13009076,\n",
       "       -0.09233826,  0.17124447, -0.2293535 , -0.26929894,  0.1723657 ,\n",
       "        0.07458858,  0.28109425, -0.05029478,  0.07022855, -0.03831661,\n",
       "       -0.19136898,  0.00281313, -0.1821378 , -0.04494851,  0.06126294,\n",
       "       -0.16049823,  0.20776838, -0.14151977,  0.07685311,  0.24039015,\n",
       "       -0.01781929,  0.2138322 ,  0.05959946,  0.02573213, -0.06294809,\n",
       "        0.01571012,  0.17389494,  0.05153542,  0.01295374,  0.391881  ,\n",
       "       -0.26595113,  0.04355697,  0.0809331 , -0.19625287, -0.11125766,\n",
       "       -0.08714263, -0.33182862,  0.08558129,  0.08199711,  0.13086435,\n",
       "        0.18931437,  0.1764489 , -0.04783812,  0.11512655,  0.31623784,\n",
       "       -0.42591894, -0.0309843 ,  0.13168748, -0.13757539,  0.15762964,\n",
       "       -0.0552502 ,  0.04201992,  0.07914263,  0.21001649, -0.11375304,\n",
       "       -0.21851467,  0.23593773, -0.27055323,  0.12052384,  0.01049154,\n",
       "       -0.25495198, -0.05477744, -0.05861719, -0.03867611, -0.0319867 ,\n",
       "       -0.1256431 , -0.11676891,  0.18489939,  0.08749337,  0.06923953],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector('one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['size)',\n",
       " '100',\n",
       " 'Option(\"h\"',\n",
       " '\"help\"',\n",
       " 'options\"))',\n",
       " 'useful',\n",
       " 'advised',\n",
       " 'force',\n",
       " 'grab',\n",
       " 'Css()',\n",
       " 'hide/show',\n",
       " 'supplied',\n",
       " 'Pane(new',\n",
       " 'Fool',\n",
       " 'thinking',\n",
       " 'expandable',\n",
       " 'Expandable',\n",
       " 'Content(new',\n",
       " 'Component}',\n",
       " 'Opening()']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
