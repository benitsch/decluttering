{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Bidirectional, TimeDistributed,Conv1D, MaxPooling1D, Input, concatenate\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.layers import GRU, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "import keras\n",
    "import os\n",
    "import tarfile\n",
    "import re\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "import statistics\n",
    "\n",
    "max_length = 50\n",
    "vocab_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(maxlen = 50, max_features = 4590, embed_size =32):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, embed_size, input_length=maxlen))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(GRU(16,dropout=0.2,return_sequences=True))\n",
    "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
    "    model.add(Flatten())\n",
    "#     model.add(Dense(8, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "def CNN(maxlen=50, max_features=4590, embed_size=32):\n",
    "    # Inputs\n",
    "    comment_seq = Input(shape=[maxlen], name='x_seq')\n",
    "\n",
    "    # Embeddings layers\n",
    "    emb_comment = Embedding(max_features, embed_size)(comment_seq)\n",
    "\n",
    "    # conv layers\n",
    "    convs = []\n",
    "#     filter_sizes = [2, 3, 4, 5]\n",
    "    filter_sizes = [2, 3]\n",
    "\n",
    "    for fsz in filter_sizes:\n",
    "        l_conv = Conv1D(filters=10, kernel_size=fsz, activation='relu')(emb_comment)\n",
    "        l_pool = MaxPooling1D(maxlen - fsz + 1)(l_conv)\n",
    "        l_pool = Flatten()(l_pool)\n",
    "        convs.append(l_pool)\n",
    "    merge = concatenate(convs, axis=1)\n",
    "\n",
    "    out = Dropout(0.2)(merge)\n",
    "    output = Dense(16, activation='relu')(out)\n",
    "\n",
    "    output = Dense(units=1, activation='sigmoid')(output)\n",
    "\n",
    "    model = Model([comment_seq], output)\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "def embedding(maxlen=50, max_features=4590, embed_size=16):\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, embed_size, input_length=maxlen))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # summarize the model\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "    \n",
    "def model_fit(model,padded_docs,labels,train_index,test_index, epochs = 5):\n",
    "    len_train = len(train_index)\n",
    "    len_test = len(test_index)\n",
    "    x_test =  np.zeros(shape = (len_test,len(padded_docs[0])))\n",
    "    y_test = np.zeros(shape = (len_test))\n",
    "    x_train = np.zeros(shape = (len_train,len(padded_docs[0])))\n",
    "    y_train = np.zeros(shape = (len_train))\n",
    "    i = 0\n",
    "    for tri in train_index:\n",
    "        x_train[i] = padded_docs[tri]\n",
    "        y_train[i] = labels[tri]\n",
    "        i+=1\n",
    "    j = 0\n",
    "    for ti in test_index:\n",
    "        x_test[j] = padded_docs[ti]\n",
    "        y_test[j] =  labels[ti]\n",
    "        j +=1\n",
    "        \n",
    "    print(\"Test set from \",test_index[0], \" to \",test_index[-1])\n",
    "\n",
    "    model.fit(x_train, y_train,epochs=epochs)\n",
    "    eva = model.evaluate(x_test,y_test)\n",
    "    print('loss: ',eva[0])\n",
    "    print('accuracy: ',eva[1])\n",
    "    print('precision: ',eva[2])\n",
    "    print('recall: ',eva[3])\n",
    "    print('f1-score: ',(2*eva[3]*eva[2])/(eva[3]+eva[2]))\n",
    "    return model ,eva\n",
    "\n",
    "def model_fit_no_test(model,x_train,y_train, epochs = 5):\n",
    "    \n",
    "    model.fit(x_train, y_train,epochs=epochs)\n",
    "    return model \n",
    "\n",
    "import numpy\n",
    "def predict_test(model, testData):\n",
    "    test = numpy.reshape(testData,(1,testData.shape[0]))\n",
    "    pr = model.predict(test)\n",
    "    re = []\n",
    "    if (pr >= 0.5):\n",
    "        return (\"yes\")\n",
    "    else:\n",
    "        return (\"no\")\n",
    "    \n",
    "def predict_train(model, testData, truth):\n",
    "    test = numpy.reshape(testData,(1,testData.shape[0]))\n",
    "    pr = model.predict(test)\n",
    "    print(\"==================\")\n",
    "    print(\"truth = \",truth )\n",
    "    print(\"predict = \",pr )\n",
    "    if (pr >= 0.5 and truth == 1) or (pr< 0.5 and truth ==0):\n",
    "        print(\"true\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"false\")\n",
    "        return 0\n",
    "    \n",
    "def write_result(predict, outPath,inpath =\"assets/test_set_0520.csv\"):\n",
    "    dataframe_in = pd.read_csv(inpath, na_filter = False)\n",
    "    dataframe_in[\"Expected\"] = predict\n",
    "    dataframe_in.to_csv(outPath)\n",
    "\n",
    "def getMedian(textList):\n",
    "     return statistics.median(textList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demostrateData():\n",
    "    SPL = \"<SPL>\"\n",
    "    path = \"csv/trimedValues2.csv\"\n",
    "    train_file = path\n",
    "    dataframe = pd.read_csv(path, na_filter = False)\n",
    "    docs = []\n",
    "    labels = []\n",
    "    for i,data in dataframe.iterrows():\n",
    "        d = data[\"comment\"]\n",
    "        c = data[\"code\"]\n",
    "        s = []\n",
    "        s =  d+\" \"+SPL+\" \"+c # comment and code together\n",
    "        docs.append(s)\n",
    "        l = 1 if data[\"non-information\"] == \"yes\" else 0\n",
    "        labels.append(l)\n",
    "    # integer encode the documents\n",
    "    vocab_size = 2000\n",
    "    encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "    # pad documents to a max length of 41 words\n",
    "    # The langest sentence contains 200 words but the Average is 21. If  padding all sentence to length of langest one, most of sentence\n",
    "    # will be 0. That is not good for RNN, so we set padding length to 50\n",
    "    summ = 0 \n",
    "    li = []\n",
    "    for t in encoded_docs:\n",
    "        li.append(len(t))\n",
    "        summ += len(t)\n",
    "    avg = summ/len(encoded_docs)\n",
    "    print(\"avg =\", avg )\n",
    "    m = getMedian(li)\n",
    "    print(\"median = \",m)\n",
    "    maxLen = len(max(docs, key=len).split())\n",
    "    print(\"max = \",maxLen)\n",
    "    li.sort()\n",
    "    ## plot graph\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    plt.style.use('ggplot')\n",
    "\n",
    "    x = range(len(encoded_docs))\n",
    "\n",
    "    plt.bar(x, li, color='green')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg = 21.787185354691076\n",
      "median =  18\n",
      "max =  199\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "demostrateData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most length of given training sentence is less than 50. So we set 50 as padding length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents\n",
    "## read train Data\n",
    "def read_train_Data():\n",
    "    SPL = \"<SPL>\"\n",
    "    path = \"csv/trimedValues2.csv\"\n",
    "    train_file = path\n",
    "    dataframe = pd.read_csv(path, na_filter = False)\n",
    "    docs = []\n",
    "    labels = []\n",
    "    for i,data in dataframe.iterrows():\n",
    "        d = data[\"comment\"]\n",
    "        c = data[\"code\"]\n",
    "        s = []\n",
    "        s =  d+\" \"+SPL+\" \"+c # comment and code together\n",
    "        docs.append(s)\n",
    "        l = 1 if data[\"non-information\"] == \"yes\" else 0\n",
    "        labels.append(l)\n",
    "    # integer encode the documents\n",
    "    vocab_size = 2000\n",
    "    encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "    # pad documents to a max length of 41 words\n",
    "    # The langest sentence contains 200 words but the Average is 21. If  padding all sentence to length of langest one, most of sentence\n",
    "    # will be 0. That is not good for RNN, so we set padding length to 50\n",
    "    li = []\n",
    "    for t in encoded_docs:\n",
    "        li.append(len(t))\n",
    "    m = getMedian(li)\n",
    "    # max_length = len(max(docs, key=len).split())\n",
    "    max_length = 50\n",
    "    ##\n",
    "    padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "    return padded_docs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents\n",
    "## read test Data\n",
    "def read_test_Data():\n",
    "    SPL = \"<SPL>\"\n",
    "    tes_path = \"csv/trimedValues3.csv\"\n",
    "    test_file = tes_path\n",
    "    dataframe = pd.read_csv(test_file, na_filter = False)\n",
    "    test_docs = []\n",
    "    test_labels = []\n",
    "    for i,data in dataframe.iterrows():\n",
    "        d = data[\"comment\"]\n",
    "        c = data[\"code\"]\n",
    "        s = []\n",
    "        s =  d+\" \"+SPL+\" \"+c # comment and code together\n",
    "        test_docs.append(s)\n",
    "    # integer encode the documents\n",
    "    vocab_size = 2000\n",
    "    test_encoded_docs = [one_hot(d, vocab_size) for d in test_docs]\n",
    "    # pad documents to a max length of 41 words\n",
    "    # The langest sentence contains 200 words but the Average is 21. If  padding all sentence to length of langest one, most of sentence\n",
    "    # will be 0. That is not good for RNN, so we set padding length to 50\n",
    "    summ = 0\n",
    "    for i in test_docs:\n",
    "        summ += len(i.split())\n",
    "#     print(summ/len(test_docs))\n",
    "    # max_length = len(max(docs, key=len).split())\n",
    "    max_length = 50\n",
    "    ##\n",
    "    test_padded_docs = pad_sequences(test_encoded_docs, maxlen=max_length, padding='post')\n",
    "    return test_padded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.7673531655225\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x_seq (InputLayer)              (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 50, 32)       64000       x_seq[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 49, 10)       650         embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 48, 10)       970         embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 1, 10)        0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 1, 10)        0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 10)           0           max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 10)           0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 20)           0           flatten_16[0][0]                 \n",
      "                                                                 flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 20)           0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 16)           336         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            17          dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 65,973\n",
      "Trainable params: 65,973\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "1311/1311 [==============================] - 1s 912us/step - loss: 0.6388 - accuracy: 0.6812 - precision_10: 0.2405 - recall_10: 0.0504\n",
      "Epoch 2/5\n",
      "1311/1311 [==============================] - 0s 315us/step - loss: 0.5486 - accuracy: 0.7216 - precision_10: 1.0000 - recall_10: 0.0318\n",
      "Epoch 3/5\n",
      "1311/1311 [==============================] - 0s 308us/step - loss: 0.4833 - accuracy: 0.7574 - precision_10: 0.9683 - recall_10: 0.1618\n",
      "Epoch 4/5\n",
      "1311/1311 [==============================] - 0s 314us/step - loss: 0.4144 - accuracy: 0.7994 - precision_10: 0.8750 - recall_10: 0.3528\n",
      "Epoch 5/5\n",
      "1311/1311 [==============================] - 0s 305us/step - loss: 0.3315 - accuracy: 0.8818 - precision_10: 0.8936 - recall_10: 0.6684\n"
     ]
    }
   ],
   "source": [
    "# train CNN with training data\n",
    "\n",
    "padded_docs,labels = read_train_Data()\n",
    "model_CNN = CNN(max_length,vocab_size,32)\n",
    "model_CNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',keras.metrics.Precision(),keras.metrics.Recall()])\n",
    "model_CNN = model_fit_no_test(model_CNN,padded_docs,labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Predicted non-informative  ['no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']\n"
     ]
    }
   ],
   "source": [
    "## CNN test\n",
    "test_padded_docs = read_test_Data()\n",
    "outPath = \"result/CNN-Result.txt\"\n",
    "i = []\n",
    "for tr in (test_padded_docs):\n",
    "    i.append(predict_test(model_CNN,tr))\n",
    "print(\"CNN Predicted non-informative \",i)\n",
    "write_result(i, outPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_53 (Embedding)     (None, 50, 32)            64000     \n",
      "_________________________________________________________________\n",
      "gru_39 (GRU)                 (None, 50, 16)            2352      \n",
      "_________________________________________________________________\n",
      "seq_self_attention_38 (SeqSe (None, 50, 16)            1089      \n",
      "_________________________________________________________________\n",
      "flatten_61 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1)                 801       \n",
      "=================================================================\n",
      "Total params: 68,242\n",
      "Trainable params: 68,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "1311/1311 [==============================] - 9s 7ms/step - loss: 0.6819 - accuracy: 0.6857 - precision_48: 0.3504 - recall_48: 0.1088\n",
      "Epoch 2/20\n",
      "1311/1311 [==============================] - 6s 5ms/step - loss: 0.6403 - accuracy: 0.7124 - precision_48: 0.0000e+00 - recall_48: 0.0000e+00\n",
      "Epoch 3/20\n",
      "1311/1311 [==============================] - 6s 5ms/step - loss: 0.6093 - accuracy: 0.7124 - precision_48: 0.0000e+00 - recall_48: 0.0000e+00\n",
      "Epoch 4/20\n",
      "1311/1311 [==============================] - 6s 5ms/step - loss: 0.5879 - accuracy: 0.7124 - precision_48: 0.0000e+00 - recall_48: 0.0000e+00\n",
      "Epoch 5/20\n",
      "1311/1311 [==============================] - 6s 5ms/step - loss: 0.5566 - accuracy: 0.7124 - precision_48: 0.0000e+00 - recall_48: 0.0000e+00\n",
      "Epoch 6/20\n",
      "1311/1311 [==============================] - 6s 4ms/step - loss: 0.5109 - accuracy: 0.7307 - precision_48: 0.8750 - recall_48: 0.0743\n",
      "Epoch 7/20\n",
      "1311/1311 [==============================] - 6s 5ms/step - loss: 0.4603 - accuracy: 0.7704 - precision_48: 0.7969 - recall_48: 0.2706\n",
      "Epoch 8/20\n",
      "1311/1311 [==============================] - 6s 5ms/step - loss: 0.4221 - accuracy: 0.8009 - precision_48: 0.7132 - recall_48: 0.5146\n",
      "Epoch 9/20\n",
      "1311/1311 [==============================] - 6s 5ms/step - loss: 0.3975 - accuracy: 0.8169 - precision_48: 0.7491 - recall_48: 0.5464\n",
      "Epoch 10/20\n",
      "1311/1311 [==============================] - 6s 4ms/step - loss: 0.3742 - accuracy: 0.8307 - precision_48: 0.7341 - recall_48: 0.6446\n",
      "Epoch 11/20\n",
      "1311/1311 [==============================] - 6s 5ms/step - loss: 0.3511 - accuracy: 0.8413 - precision_48: 0.7522 - recall_48: 0.6684\n",
      "Epoch 12/20\n",
      "1311/1311 [==============================] - 6s 5ms/step - loss: 0.3316 - accuracy: 0.8459 - precision_48: 0.7596 - recall_48: 0.6790\n",
      "Epoch 13/20\n",
      "1311/1311 [==============================] - 6s 4ms/step - loss: 0.3056 - accuracy: 0.8558 - precision_48: 0.7670 - recall_48: 0.7162\n",
      "Epoch 14/20\n",
      "1311/1311 [==============================] - 6s 4ms/step - loss: 0.2869 - accuracy: 0.8841 - precision_48: 0.8134 - recall_48: 0.7745\n",
      "Epoch 15/20\n",
      "1311/1311 [==============================] - 6s 5ms/step - loss: 0.2676 - accuracy: 0.8879 - precision_48: 0.8059 - recall_48: 0.8037\n",
      "Epoch 16/20\n",
      "1311/1311 [==============================] - 6s 5ms/step - loss: 0.2442 - accuracy: 0.9016 - precision_48: 0.8263 - recall_48: 0.8329\n",
      "Epoch 17/20\n",
      "1311/1311 [==============================] - 6s 4ms/step - loss: 0.2247 - accuracy: 0.9115 - precision_48: 0.8390 - recall_48: 0.8568\n",
      "Epoch 18/20\n",
      "1311/1311 [==============================] - 6s 5ms/step - loss: 0.2115 - accuracy: 0.9199 - precision_48: 0.8523 - recall_48: 0.8727\n",
      "Epoch 19/20\n",
      "1311/1311 [==============================] - 6s 5ms/step - loss: 0.1967 - accuracy: 0.9237 - precision_48: 0.8437 - recall_48: 0.9019\n",
      "Epoch 20/20\n",
      "1311/1311 [==============================] - 6s 4ms/step - loss: 0.1823 - accuracy: 0.9329 - precision_48: 0.8793 - recall_48: 0.8886\n"
     ]
    }
   ],
   "source": [
    "# train RNN with training data\n",
    "padded_docs,labels = read_train_Data()\n",
    "model = RNN(max_length,vocab_size,32)\n",
    "learning_rate = 0.0002\n",
    "adam = Adam(\n",
    "    learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False\n",
    "    )\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy',keras.metrics.Precision(),keras.metrics.Recall()])\n",
    "model = model_fit_no_test(model,padded_docs,labels, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN Predicted non-informative  ['no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes']\n"
     ]
    }
   ],
   "source": [
    "## RNN test\n",
    "test_padded_docs = read_test_Data()\n",
    "\n",
    "i = []\n",
    "for tr in (test_padded_docs):\n",
    "    i.append(predict_test(model,tr))\n",
    "print(\"RNN Predicted non-informative \",i)\n",
    "outPath = \"result/RNN-Result.txt\"\n",
    "write_result(i, outPath,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.7673531655225\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 50, 32)            64000     \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 1601      \n",
      "=================================================================\n",
      "Total params: 65,601\n",
      "Trainable params: 65,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "1311/1311 [==============================] - 1s 640us/step - loss: 0.6330 - accuracy: 0.6972 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1311/1311 [==============================] - 0s 194us/step - loss: 0.5432 - accuracy: 0.7429 - precision_14: 0.7273 - recall_14: 0.1698\n",
      "Epoch 3/5\n",
      "1311/1311 [==============================] - 0s 195us/step - loss: 0.4707 - accuracy: 0.7727 - precision_14: 0.6695 - recall_14: 0.4138\n",
      "Epoch 4/5\n",
      "1311/1311 [==============================] - 0s 203us/step - loss: 0.4165 - accuracy: 0.8024 - precision_14: 0.7360 - recall_14: 0.4881\n",
      "Epoch 5/5\n",
      "1311/1311 [==============================] - 0s 199us/step - loss: 0.3666 - accuracy: 0.8314 - precision_14: 0.7847 - recall_14: 0.5703\n"
     ]
    }
   ],
   "source": [
    "# train embedding with training data\n",
    "padded_docs,labels = read_train_Data()\n",
    "model_em = embedding(max_length,vocab_size,32)\n",
    "model_em.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',keras.metrics.Precision(),keras.metrics.Recall()])\n",
    "model_em = model_fit_no_test(model_em,padded_docs,labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Predicted non-informative  ['no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no']\n"
     ]
    }
   ],
   "source": [
    "## embedding test\n",
    "test_padded_docs = read_test_Data()\n",
    "\n",
    "i = []\n",
    "for tr in (test_padded_docs):\n",
    "    i.append(predict_test(model_em,tr))\n",
    "print(\"Embedding Predicted non-informative \",i)\n",
    "outPath = \"result/Embedding-Result.txt\"\n",
    "write_result(i, outPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x_seq (InputLayer)              (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_47 (Embedding)        (None, 50, 32)       64000       x_seq[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 49, 10)       650         embedding_47[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 48, 10)       970         embedding_47[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 1, 10)        0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 1, 10)        0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_50 (Flatten)            (None, 10)           0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_51 (Flatten)            (None, 10)           0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 20)           0           flatten_50[0][0]                 \n",
      "                                                                 flatten_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 20)           0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 16)           336         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 1)            17          dense_50[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 65,973\n",
      "Trainable params: 65,973\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Test set from  0  to  262\n",
      "Epoch 1/5\n",
      "1048/1048 [==============================] - 3s 3ms/step - loss: 0.6259 - accuracy: 0.6985 - precision_42: 1.0000 - recall_42: 0.0032\n",
      "Epoch 2/5\n",
      "1048/1048 [==============================] - 0s 448us/step - loss: 0.5540 - accuracy: 0.7013 - precision_42: 1.0000 - recall_42: 0.0126  \n",
      "Epoch 3/5\n",
      "1048/1048 [==============================] - 0s 430us/step - loss: 0.4966 - accuracy: 0.7462 - precision_42: 1.0000 - recall_42: 0.1609\n",
      "Epoch 4/5\n",
      "1048/1048 [==============================] - 0s 438us/step - loss: 0.4311 - accuracy: 0.7824 - precision_42: 0.9588 - recall_42: 0.2934\n",
      "Epoch 5/5\n",
      "1048/1048 [==============================] - 0s 458us/step - loss: 0.3538 - accuracy: 0.8435 - precision_42: 0.9227 - recall_42: 0.5268\n",
      "263/263 [==============================] - 2s 8ms/step\n",
      "loss:  0.4389187174604873\n",
      "accuracy:  0.7946767807006836\n",
      "precision:  0.5789473652839661\n",
      "recall:  0.36666667461395264\n",
      "f1-score:  0.44897959685136946\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x_seq (InputLayer)              (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_48 (Embedding)        (None, 50, 32)       64000       x_seq[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 49, 10)       650         embedding_48[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 48, 10)       970         embedding_48[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 1, 10)        0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 1, 10)        0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_52 (Flatten)            (None, 10)           0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_53 (Flatten)            (None, 10)           0           max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 20)           0           flatten_52[0][0]                 \n",
      "                                                                 flatten_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 20)           0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 16)           336         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 1)            17          dense_52[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 65,973\n",
      "Trainable params: 65,973\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Test set from  263  to  524\n",
      "Epoch 1/5\n",
      "1049/1049 [==============================] - 3s 3ms/step - loss: 0.6295 - accuracy: 0.6969 - precision_43: 0.2222 - recall_43: 0.0064\n",
      "Epoch 2/5\n",
      "1049/1049 [==============================] - 0s 460us/step - loss: 0.5574 - accuracy: 0.7016 - precision_43: 0.0000e+00 - recall_43: 0.0000e+00\n",
      "Epoch 3/5\n",
      "1049/1049 [==============================] - 0s 457us/step - loss: 0.5110 - accuracy: 0.7216 - precision_43: 1.0000 - recall_43: 0.0671\n",
      "Epoch 4/5\n",
      "1049/1049 [==============================] - 0s 442us/step - loss: 0.4601 - accuracy: 0.7531 - precision_43: 1.0000 - recall_43: 0.1725\n",
      "Epoch 5/5\n",
      "1049/1049 [==============================] - 0s 435us/step - loss: 0.3976 - accuracy: 0.8027 - precision_43: 0.9649 - recall_43: 0.3514\n",
      "262/262 [==============================] - 2s 8ms/step\n",
      "loss:  0.4606083731614906\n",
      "accuracy:  0.7786259651184082\n",
      "precision:  0.6499999761581421\n",
      "recall:  0.203125\n",
      "f1-score:  0.30952380682065095\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x_seq (InputLayer)              (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_49 (Embedding)        (None, 50, 32)       64000       x_seq[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 49, 10)       650         embedding_49[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 48, 10)       970         embedding_49[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 1, 10)        0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 1, 10)        0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_54 (Flatten)            (None, 10)           0           max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_55 (Flatten)            (None, 10)           0           max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 20)           0           flatten_54[0][0]                 \n",
      "                                                                 flatten_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 20)           0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 16)           336         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 1)            17          dense_54[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 65,973\n",
      "Trainable params: 65,973\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set from  525  to  786\n",
      "Epoch 1/5\n",
      "1049/1049 [==============================] - 3s 3ms/step - loss: 0.6312 - accuracy: 0.7121 - precision_44: 0.0000e+00 - recall_44: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1049/1049 [==============================] - 0s 475us/step - loss: 0.5514 - accuracy: 0.7121 - precision_44: 0.0000e+00 - recall_44: 0.0000e+00\n",
      "Epoch 3/5\n",
      "1049/1049 [==============================] - 1s 488us/step - loss: 0.4980 - accuracy: 0.7312 - precision_44: 1.0000 - recall_44: 0.0662\n",
      "Epoch 4/5\n",
      "1049/1049 [==============================] - 1s 487us/step - loss: 0.4494 - accuracy: 0.7598 - precision_44: 1.0000 - recall_44: 0.1656\n",
      "Epoch 5/5\n",
      "1049/1049 [==============================] - 0s 475us/step - loss: 0.3833 - accuracy: 0.8246 - precision_44: 0.9155 - recall_44: 0.4305\n",
      "262/262 [==============================] - 2s 8ms/step\n",
      "loss:  0.44777069883492154\n",
      "accuracy:  0.7366412281990051\n",
      "precision:  0.6499999761581421\n",
      "recall:  0.1733333319425583\n",
      "f1-score:  0.27368420667925697\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x_seq (InputLayer)              (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_50 (Embedding)        (None, 50, 32)       64000       x_seq[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 49, 10)       650         embedding_50[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 48, 10)       970         embedding_50[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 1, 10)        0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 1, 10)        0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_56 (Flatten)            (None, 10)           0           max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_57 (Flatten)            (None, 10)           0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 20)           0           flatten_56[0][0]                 \n",
      "                                                                 flatten_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 20)           0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 16)           336         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 1)            17          dense_56[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 65,973\n",
      "Trainable params: 65,973\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Test set from  787  to  1048\n",
      "Epoch 1/5\n",
      "1049/1049 [==============================] - 3s 3ms/step - loss: 0.6688 - accuracy: 0.6816 - precision_45: 0.2479 - recall_45: 0.1099\n",
      "Epoch 2/5\n",
      "1049/1049 [==============================] - 0s 476us/step - loss: 0.5907 - accuracy: 0.7398 - precision_45: 0.0000e+00 - recall_45: 0.0000e+00\n",
      "Epoch 3/5\n",
      "1049/1049 [==============================] - 0s 467us/step - loss: 0.5265 - accuracy: 0.7398 - precision_45: 0.0000e+00 - recall_45: 0.0000e+00\n",
      "Epoch 4/5\n",
      "1049/1049 [==============================] - 0s 470us/step - loss: 0.4848 - accuracy: 0.7398 - precision_45: 0.0000e+00 - recall_45: 0.0000e+00\n",
      "Epoch 5/5\n",
      "1049/1049 [==============================] - 1s 482us/step - loss: 0.4316 - accuracy: 0.7636 - precision_45: 0.9032 - recall_45: 0.1026\n",
      "262/262 [==============================] - 2s 8ms/step\n",
      "loss:  0.49251333629811994\n",
      "accuracy:  0.8129770755767822\n",
      "precision:  0.9661017060279846\n",
      "recall:  0.5480769276618958\n",
      "f1-score:  0.6993865097124076\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x_seq (InputLayer)              (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_51 (Embedding)        (None, 50, 32)       64000       x_seq[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 49, 10)       650         embedding_51[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 48, 10)       970         embedding_51[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 1, 10)        0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling1D) (None, 1, 10)        0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_58 (Flatten)            (None, 10)           0           max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_59 (Flatten)            (None, 10)           0           max_pooling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 20)           0           flatten_58[0][0]                 \n",
      "                                                                 flatten_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 20)           0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 16)           336         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 1)            17          dense_58[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 65,973\n",
      "Trainable params: 65,973\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Test set from  1049  to  1310\n",
      "Epoch 1/5\n",
      "1049/1049 [==============================] - 3s 3ms/step - loss: 0.6440 - accuracy: 0.7092 - precision_46: 0.0000e+00 - recall_46: 0.0000e+00\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049/1049 [==============================] - 0s 450us/step - loss: 0.5628 - accuracy: 0.7112 - precision_46: 0.0000e+00 - recall_46: 0.0000e+00 0s - loss: 0.5725 - accuracy: 0.7058 - precision_46: 0.0000e+00 - recall_46: 0.0000e+0\n",
      "Epoch 3/5\n",
      "1049/1049 [==============================] - 0s 453us/step - loss: 0.5030 - accuracy: 0.7178 - precision_46: 1.0000 - recall_46: 0.0231\n",
      "Epoch 4/5\n",
      "1049/1049 [==============================] - 0s 456us/step - loss: 0.4377 - accuracy: 0.7703 - precision_46: 0.9079 - recall_46: 0.2277\n",
      "Epoch 5/5\n",
      "1049/1049 [==============================] - 0s 448us/step - loss: 0.3696 - accuracy: 0.8398 - precision_46: 0.9042 - recall_46: 0.4983\n",
      "262/262 [==============================] - 2s 8ms/step\n",
      "loss:  0.4956837246436199\n",
      "accuracy:  0.7557252049446106\n",
      "precision:  0.6666666865348816\n",
      "recall:  0.2702702581882477\n",
      "f1-score:  0.3846153756879133\n",
      "total loss:  0.46709897007972784\n",
      "total accuracy:  0.7757292509078979\n",
      "total precision:  0.7023431420326233\n",
      "total recall:  0.31229443848133087\n",
      "total f1-score:  0.4232378991503197\n"
     ]
    }
   ],
   "source": [
    "# CNN train with split \n",
    "max_length = 50\n",
    "vocab_size = 2000\n",
    "padded_docs, labels = read_train_Data()\n",
    "i = 0\n",
    "n_split=5\n",
    "loss = 0\n",
    "accuracy = 0\n",
    "precision = 0\n",
    "recall = 0\n",
    "f1_score = 0\n",
    "for train_index,test_index in KFold(n_split).split(padded_docs):\n",
    "    # define the model\n",
    "    model = CNN(max_length,vocab_size,32)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',keras.metrics.Precision(),keras.metrics.Recall()])\n",
    "\n",
    "    model,eva = model_fit(model,padded_docs,labels,train_index,test_index)\n",
    "    loss += eva[0]\n",
    "    accuracy += eva[1]\n",
    "    precision += eva[2]\n",
    "    recall += eva[3]\n",
    "    if precision + recall != 0:\n",
    "        f1_score += (2*eva[3]*eva[2])/(eva[3]+eva[2])\n",
    "\n",
    "print('total loss: ',loss/n_split)\n",
    "print('total accuracy: ',accuracy/n_split)\n",
    "print('total precision: ',precision/n_split)\n",
    "print('total recall: ',recall/n_split)\n",
    "print('total f1-score: ',f1_score/n_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.7673531655225\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 50, 32)            64000     \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 1601      \n",
      "=================================================================\n",
      "Total params: 65,601\n",
      "Trainable params: 65,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test set from  0  to  262\n",
      "Epoch 1/5\n",
      "1048/1048 [==============================] - 1s 750us/step - loss: 0.6455 - accuracy: 0.6803 - precision_7: 0.4022 - recall_7: 0.1167\n",
      "Epoch 2/5\n",
      "1048/1048 [==============================] - 0s 219us/step - loss: 0.5608 - accuracy: 0.7242 - precision_7: 0.9118 - recall_7: 0.0978\n",
      "Epoch 3/5\n",
      "1048/1048 [==============================] - 0s 209us/step - loss: 0.4765 - accuracy: 0.7910 - precision_7: 0.7207 - recall_7: 0.5047\n",
      "Epoch 4/5\n",
      "1048/1048 [==============================] - 0s 207us/step - loss: 0.4250 - accuracy: 0.7920 - precision_7: 0.7143 - recall_7: 0.5205\n",
      "Epoch 5/5\n",
      "1048/1048 [==============================] - 0s 215us/step - loss: 0.3738 - accuracy: 0.8302 - precision_7: 0.7837 - recall_7: 0.6057\n",
      "263/263 [==============================] - 0s 2ms/step\n",
      "loss:  0.48288314843359104\n",
      "accuracy:  0.7680608630180359\n",
      "precision:  0.4888888895511627\n",
      "recall:  0.36666667461395264\n",
      "f1-score:  0.41904762448096755\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 50, 32)            64000     \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 1601      \n",
      "=================================================================\n",
      "Total params: 65,601\n",
      "Trainable params: 65,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test set from  263  to  524\n",
      "Epoch 1/5\n",
      "1049/1049 [==============================] - 1s 761us/step - loss: 0.6411 - accuracy: 0.6835 - precision_8: 0.1200 - recall_8: 0.0096\n",
      "Epoch 2/5\n",
      "1049/1049 [==============================] - 0s 215us/step - loss: 0.5535 - accuracy: 0.7274 - precision_8: 0.8293 - recall_8: 0.1086 \n",
      "Epoch 3/5\n",
      "1049/1049 [==============================] - 0s 215us/step - loss: 0.4722 - accuracy: 0.7855 - precision_8: 0.7391 - recall_8: 0.4345\n",
      "Epoch 4/5\n",
      "1049/1049 [==============================] - 0s 227us/step - loss: 0.4236 - accuracy: 0.7998 - precision_8: 0.7229 - recall_8: 0.5335\n",
      "Epoch 5/5\n",
      "1049/1049 [==============================] - 0s 235us/step - loss: 0.3827 - accuracy: 0.8236 - precision_8: 0.7540 - recall_8: 0.6070\n",
      "262/262 [==============================] - 0s 2ms/step\n",
      "loss:  0.48973994696413287\n",
      "accuracy:  0.7633587718009949\n",
      "precision:  0.5178571343421936\n",
      "recall:  0.453125\n",
      "f1-score:  0.48333332962459985\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 50, 32)            64000     \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 1601      \n",
      "=================================================================\n",
      "Total params: 65,601\n",
      "Trainable params: 65,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test set from  525  to  786\n",
      "Epoch 1/5\n",
      "1049/1049 [==============================] - 1s 779us/step - loss: 0.6482 - accuracy: 0.6902 - precision_9: 0.3175 - recall_9: 0.0662\n",
      "Epoch 2/5\n",
      "1049/1049 [==============================] - 0s 211us/step - loss: 0.5656 - accuracy: 0.7274 - precision_9: 1.0000 - recall_9: 0.0530\n",
      "Epoch 3/5\n",
      "1049/1049 [==============================] - 0s 219us/step - loss: 0.4881 - accuracy: 0.7817 - precision_9: 0.7483 - recall_9: 0.3642\n",
      "Epoch 4/5\n",
      "1049/1049 [==============================] - 0s 214us/step - loss: 0.4300 - accuracy: 0.7969 - precision_9: 0.7214 - recall_9: 0.4801\n",
      "Epoch 5/5\n",
      "1049/1049 [==============================] - 0s 229us/step - loss: 0.3837 - accuracy: 0.8160 - precision_9: 0.7422 - recall_9: 0.5530\n",
      "262/262 [==============================] - 0s 2ms/step\n",
      "loss:  0.45209050861023764\n",
      "accuracy:  0.7709923386573792\n",
      "precision:  0.7419354915618896\n",
      "recall:  0.30666667222976685\n",
      "f1-score:  0.4339622710365636\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 50, 32)            64000     \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 1601      \n",
      "=================================================================\n",
      "Total params: 65,601\n",
      "Trainable params: 65,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test set from  787  to  1048\n",
      "Epoch 1/5\n",
      "1049/1049 [==============================] - 1s 852us/step - loss: 0.6206 - accuracy: 0.7331 - precision_10: 0.2308 - recall_10: 0.0110\n",
      "Epoch 2/5\n",
      "1049/1049 [==============================] - 0s 215us/step - loss: 0.5553 - accuracy: 0.7417 - precision_10: 1.0000 - recall_10: 0.0073\n",
      "Epoch 3/5\n",
      "1049/1049 [==============================] - 0s 208us/step - loss: 0.5034 - accuracy: 0.7464 - precision_10: 0.8182 - recall_10: 0.0330\n",
      "Epoch 4/5\n",
      "1049/1049 [==============================] - 0s 206us/step - loss: 0.4481 - accuracy: 0.7827 - precision_10: 0.6957 - recall_10: 0.2930\n",
      "Epoch 5/5\n",
      "1049/1049 [==============================] - 0s 210us/step - loss: 0.4020 - accuracy: 0.8065 - precision_10: 0.7160 - recall_10: 0.4249\n",
      "262/262 [==============================] - 0s 2ms/step\n",
      "loss:  0.438815837598029\n",
      "accuracy:  0.8435114622116089\n",
      "precision:  0.8705882430076599\n",
      "recall:  0.7115384340286255\n",
      "f1-score:  0.7830687695296296\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 50, 32)            64000     \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 1601      \n",
      "=================================================================\n",
      "Total params: 65,601\n",
      "Trainable params: 65,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test set from  1049  to  1310\n",
      "Epoch 1/5\n",
      "1049/1049 [==============================] - 1s 837us/step - loss: 0.6435 - accuracy: 0.6854 - precision_11: 0.1707 - recall_11: 0.0231\n",
      "Epoch 2/5\n",
      "1049/1049 [==============================] - 0s 211us/step - loss: 0.5531 - accuracy: 0.7388 - precision_11: 1.0000 - recall_11: 0.0957\n",
      "Epoch 3/5\n",
      "1049/1049 [==============================] - 0s 212us/step - loss: 0.4740 - accuracy: 0.7836 - precision_11: 0.7317 - recall_11: 0.3960\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049/1049 [==============================] - 0s 212us/step - loss: 0.4174 - accuracy: 0.8027 - precision_11: 0.7553 - recall_11: 0.4686\n",
      "Epoch 5/5\n",
      "1049/1049 [==============================] - 0s 218us/step - loss: 0.3717 - accuracy: 0.8265 - precision_11: 0.7574 - recall_11: 0.5875\n",
      "262/262 [==============================] - 0s 2ms/step\n",
      "loss:  0.4723185619325128\n",
      "accuracy:  0.7709923386573792\n",
      "precision:  0.6666666865348816\n",
      "recall:  0.37837839126586914\n",
      "f1-score:  0.48275863638814365\n",
      "total loss:  0.46716960070770075\n",
      "total accuracy:  0.7833831548690796\n",
      "total precision:  0.6571872889995575\n",
      "total recall:  0.4432750344276428\n",
      "total f1-score:  0.5204341262119808\n"
     ]
    }
   ],
   "source": [
    "# embedding train with split \n",
    "max_length = 50\n",
    "vocab_size = 2000\n",
    "padded_docs, labels = read_train_Data()\n",
    "i = 0\n",
    "n_split=5\n",
    "loss = 0\n",
    "accuracy = 0\n",
    "precision = 0\n",
    "recall = 0\n",
    "f1_score = 0\n",
    "for train_index,test_index in KFold(n_split).split(padded_docs):\n",
    "    # define the model\n",
    "    model = embedding(max_length,vocab_size,32)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',keras.metrics.Precision(),keras.metrics.Recall()])\n",
    "\n",
    "    model,eva = model_fit(model,padded_docs,labels,train_index,test_index)\n",
    "    loss += eva[0]\n",
    "    accuracy += eva[1]\n",
    "    precision += eva[2]\n",
    "    recall += eva[3]\n",
    "    f1_score += (2*eva[3]*eva[2])/(eva[3]+eva[2])\n",
    "\n",
    "print('total loss: ',loss/n_split)\n",
    "print('total accuracy: ',accuracy/n_split)\n",
    "print('total precision: ',precision/n_split)\n",
    "print('total recall: ',recall/n_split)\n",
    "print('total f1-score: ',f1_score/n_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_37 (Embedding)     (None, 50, 32)            64000     \n",
      "_________________________________________________________________\n",
      "gru_32 (GRU)                 (None, 50, 16)            2352      \n",
      "_________________________________________________________________\n",
      "seq_self_attention_31 (SeqSe (None, 50, 16)            1089      \n",
      "_________________________________________________________________\n",
      "flatten_36 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 801       \n",
      "=================================================================\n",
      "Total params: 68,242\n",
      "Trainable params: 68,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test set from  0  to  262\n",
      "Epoch 1/20\n",
      "1048/1048 [==============================] - 7s 7ms/step - loss: 0.6860 - accuracy: 0.6727 - precision_32: 0.3523 - recall_32: 0.0978\n",
      "Epoch 2/20\n",
      "1048/1048 [==============================] - 4s 4ms/step - loss: 0.6629 - accuracy: 0.6975 - precision_32: 0.0000e+00 - recall_32: 0.0000e+00\n",
      "Epoch 3/20\n",
      "1048/1048 [==============================] - 5s 5ms/step - loss: 0.6329 - accuracy: 0.6975 - precision_32: 0.0000e+00 - recall_32: 0.0000e+00\n",
      "Epoch 4/20\n",
      "1048/1048 [==============================] - 5s 4ms/step - loss: 0.6147 - accuracy: 0.6975 - precision_32: 0.0000e+00 - recall_32: 0.0000e+00\n",
      "Epoch 5/20\n",
      "1048/1048 [==============================] - 7s 7ms/step - loss: 0.5935 - accuracy: 0.6975 - precision_32: 0.0000e+00 - recall_32: 0.0000e+00\n",
      "Epoch 6/20\n",
      "1048/1048 [==============================] - 6s 6ms/step - loss: 0.5646 - accuracy: 0.6975 - precision_32: 0.0000e+00 - recall_32: 0.0000e+00\n",
      "Epoch 7/20\n",
      "1048/1048 [==============================] - 6s 6ms/step - loss: 0.5267 - accuracy: 0.7109 - precision_32: 0.9375 - recall_32: 0.0473\n",
      "Epoch 8/20\n",
      "1048/1048 [==============================] - 5s 5ms/step - loss: 0.4760 - accuracy: 0.7605 - precision_32: 0.8113 - recall_32: 0.2713\n",
      "Epoch 9/20\n",
      "1048/1048 [==============================] - 5s 5ms/step - loss: 0.4368 - accuracy: 0.7948 - precision_32: 0.7656 - recall_32: 0.4637\n",
      "Epoch 10/20\n",
      "1048/1048 [==============================] - 5s 5ms/step - loss: 0.4043 - accuracy: 0.8006 - precision_32: 0.7348 - recall_32: 0.5331\n",
      "Epoch 11/20\n",
      "1048/1048 [==============================] - 5s 5ms/step - loss: 0.3796 - accuracy: 0.8378 - precision_32: 0.7732 - recall_32: 0.6562\n",
      "Epoch 12/20\n",
      "1048/1048 [==============================] - 5s 4ms/step - loss: 0.3542 - accuracy: 0.8349 - precision_32: 0.7590 - recall_32: 0.6656\n",
      "Epoch 13/20\n",
      "1048/1048 [==============================] - 5s 4ms/step - loss: 0.3364 - accuracy: 0.8473 - precision_32: 0.7774 - recall_32: 0.6940\n",
      "Epoch 14/20\n",
      "1048/1048 [==============================] - 5s 4ms/step - loss: 0.3163 - accuracy: 0.8616 - precision_32: 0.8028 - recall_32: 0.7192\n",
      "Epoch 15/20\n",
      "1048/1048 [==============================] - 5s 5ms/step - loss: 0.2944 - accuracy: 0.8693 - precision_32: 0.7961 - recall_32: 0.7634\n",
      "Epoch 16/20\n",
      "1048/1048 [==============================] - 5s 5ms/step - loss: 0.2772 - accuracy: 0.8855 - precision_32: 0.8408 - recall_32: 0.7666\n",
      "Epoch 17/20\n",
      "1048/1048 [==============================] - 6s 5ms/step - loss: 0.2593 - accuracy: 0.8893 - precision_32: 0.8150 - recall_32: 0.8202A: 2s - loss: 0.2734 - accuracy: 0.8787 - precision_32: 0.7965 - r\n",
      "Epoch 18/20\n",
      "1048/1048 [==============================] - 5s 5ms/step - loss: 0.2406 - accuracy: 0.8960 - precision_32: 0.8312 - recall_32: 0.8233\n",
      "Epoch 19/20\n",
      "1048/1048 [==============================] - 5s 5ms/step - loss: 0.2227 - accuracy: 0.9074 - precision_32: 0.8503 - recall_32: 0.8423\n",
      "Epoch 20/20\n",
      "1048/1048 [==============================] - 6s 5ms/step - loss: 0.2078 - accuracy: 0.9132 - precision_32: 0.8466 - recall_32: 0.8707\n",
      "263/263 [==============================] - 3s 11ms/step\n",
      "loss:  0.6830545649102432\n",
      "accuracy:  0.7680608630180359\n",
      "precision:  0.4909090995788574\n",
      "recall:  0.44999998807907104\n",
      "f1-score:  0.4695652148674023\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_38 (Embedding)     (None, 50, 32)            64000     \n",
      "_________________________________________________________________\n",
      "gru_33 (GRU)                 (None, 50, 16)            2352      \n",
      "_________________________________________________________________\n",
      "seq_self_attention_32 (SeqSe (None, 50, 16)            1089      \n",
      "_________________________________________________________________\n",
      "flatten_37 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 801       \n",
      "=================================================================\n",
      "Total params: 68,242\n",
      "Trainable params: 68,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test set from  263  to  524\n",
      "Epoch 1/20\n",
      "1049/1049 [==============================] - 9s 9ms/step - loss: 0.6841 - accuracy: 0.6864 - precision_33: 0.4048 - recall_33: 0.1086\n",
      "Epoch 2/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.6572 - accuracy: 0.7016 - precision_33: 0.0000e+00 - recall_33: 0.0000e+00\n",
      "Epoch 3/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.6269 - accuracy: 0.7016 - precision_33: 0.0000e+00 - recall_33: 0.0000e+00\n",
      "Epoch 4/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.6027 - accuracy: 0.7016 - precision_33: 0.0000e+00 - recall_33: 0.0000e+00\n",
      "Epoch 5/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.5776 - accuracy: 0.7016 - precision_33: 0.0000e+00 - recall_33: 0.0000e+00\n",
      "Epoch 6/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.5404 - accuracy: 0.7083 - precision_33: 0.8889 - recall_33: 0.0256\n",
      "Epoch 7/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.4925 - accuracy: 0.7521 - precision_33: 0.8193 - recall_33: 0.2173\n",
      "Epoch 8/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.4554 - accuracy: 0.7769 - precision_33: 0.7232 - recall_33: 0.4089\n",
      "Epoch 9/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.4161 - accuracy: 0.8027 - precision_33: 0.7409 - recall_33: 0.5208\n",
      "Epoch 10/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.3853 - accuracy: 0.8255 - precision_33: 0.7519 - recall_33: 0.6198\n",
      "Epoch 11/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.3749 - accuracy: 0.8208 - precision_33: 0.7341 - recall_33: 0.6262\n",
      "Epoch 12/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.3453 - accuracy: 0.8351 - precision_33: 0.7465 - recall_33: 0.6773\n",
      "Epoch 13/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.3287 - accuracy: 0.8427 - precision_33: 0.7606 - recall_33: 0.6901\n",
      "Epoch 14/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.2935 - accuracy: 0.8627 - precision_33: 0.7807 - recall_33: 0.7508\n",
      "Epoch 15/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.2652 - accuracy: 0.8780 - precision_33: 0.8033 - recall_33: 0.7827\n",
      "Epoch 16/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.2505 - accuracy: 0.8847 - precision_33: 0.8077 - recall_33: 0.8051\n",
      "Epoch 17/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.2221 - accuracy: 0.9056 - precision_33: 0.8323 - recall_33: 0.8562\n",
      "Epoch 18/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.2030 - accuracy: 0.9113 - precision_33: 0.8374 - recall_33: 0.8722\n",
      "Epoch 19/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.1760 - accuracy: 0.9228 - precision_33: 0.8452 - recall_33: 0.9073\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.1636 - accuracy: 0.9276 - precision_33: 0.8624 - recall_33: 0.9010\n",
      "262/262 [==============================] - 2s 9ms/step\n",
      "loss:  1.0135951606371931\n",
      "accuracy:  0.7786259651184082\n",
      "precision:  0.550000011920929\n",
      "recall:  0.515625\n",
      "f1-score:  0.5322580700982497\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_39 (Embedding)     (None, 50, 32)            64000     \n",
      "_________________________________________________________________\n",
      "gru_34 (GRU)                 (None, 50, 16)            2352      \n",
      "_________________________________________________________________\n",
      "seq_self_attention_33 (SeqSe (None, 50, 16)            1089      \n",
      "_________________________________________________________________\n",
      "flatten_38 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 801       \n",
      "=================================================================\n",
      "Total params: 68,242\n",
      "Trainable params: 68,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test set from  525  to  786\n",
      "Epoch 1/20\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 0.6850 - accuracy: 0.6540 - precision_34: 0.3257 - recall_34: 0.1887\n",
      "Epoch 2/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.6536 - accuracy: 0.7121 - precision_34: 0.0000e+00 - recall_34: 0.0000e+00\n",
      "Epoch 3/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.6237 - accuracy: 0.7121 - precision_34: 0.0000e+00 - recall_34: 0.0000e+00\n",
      "Epoch 4/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.6082 - accuracy: 0.7121 - precision_34: 0.0000e+00 - recall_34: 0.0000e+00\n",
      "Epoch 5/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.5912 - accuracy: 0.7121 - precision_34: 0.0000e+00 - recall_34: 0.0000e+00\n",
      "Epoch 6/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.5655 - accuracy: 0.7121 - precision_34: 0.0000e+00 - recall_34: 0.0000e+00\n",
      "Epoch 7/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.5338 - accuracy: 0.7140 - precision_34: 1.0000 - recall_34: 0.0066\n",
      "Epoch 8/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.4974 - accuracy: 0.7398 - precision_34: 0.8222 - recall_34: 0.1225\n",
      "Epoch 9/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.4605 - accuracy: 0.7703 - precision_34: 0.8081 - recall_34: 0.2649\n",
      "Epoch 10/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.4357 - accuracy: 0.7893 - precision_34: 0.7143 - recall_34: 0.4470\n",
      "Epoch 11/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.4086 - accuracy: 0.8027 - precision_34: 0.7363 - recall_34: 0.4901\n",
      "Epoch 12/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.3883 - accuracy: 0.8093 - precision_34: 0.7107 - recall_34: 0.5695\n",
      "Epoch 13/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.3671 - accuracy: 0.8275 - precision_34: 0.7553 - recall_34: 0.5927\n",
      "Epoch 14/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.3396 - accuracy: 0.8418 - precision_34: 0.7656 - recall_34: 0.6490\n",
      "Epoch 15/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.3260 - accuracy: 0.8503 - precision_34: 0.7695 - recall_34: 0.6854\n",
      "Epoch 16/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.2983 - accuracy: 0.8627 - precision_34: 0.7904 - recall_34: 0.7119\n",
      "Epoch 17/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.2767 - accuracy: 0.8761 - precision_34: 0.7867 - recall_34: 0.7815\n",
      "Epoch 18/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.2589 - accuracy: 0.8885 - precision_34: 0.8246 - recall_34: 0.7781\n",
      "Epoch 19/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.2278 - accuracy: 0.8942 - precision_34: 0.8282 - recall_34: 0.7980\n",
      "Epoch 20/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.2062 - accuracy: 0.9180 - precision_34: 0.8462 - recall_34: 0.8742\n",
      "262/262 [==============================] - 2s 9ms/step\n",
      "loss:  0.6368633777130651\n",
      "accuracy:  0.8091602921485901\n",
      "precision:  0.7777777910232544\n",
      "recall:  0.46666666865348816\n",
      "f1-score:  0.5833333386108279\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_40 (Embedding)     (None, 50, 32)            64000     \n",
      "_________________________________________________________________\n",
      "gru_35 (GRU)                 (None, 50, 16)            2352      \n",
      "_________________________________________________________________\n",
      "seq_self_attention_34 (SeqSe (None, 50, 16)            1089      \n",
      "_________________________________________________________________\n",
      "flatten_39 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 801       \n",
      "=================================================================\n",
      "Total params: 68,242\n",
      "Trainable params: 68,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test set from  787  to  1048\n",
      "Epoch 1/20\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 0.6839 - accuracy: 0.7092 - precision_35: 0.3222 - recall_35: 0.1062\n",
      "Epoch 2/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.6462 - accuracy: 0.7398 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "Epoch 3/20\n",
      "1049/1049 [==============================] - 5s 5ms/step - loss: 0.5958 - accuracy: 0.7398 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "Epoch 4/20\n",
      "1049/1049 [==============================] - 5s 5ms/step - loss: 0.5763 - accuracy: 0.7398 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "Epoch 5/20\n",
      "1049/1049 [==============================] - 6s 5ms/step - loss: 0.5629 - accuracy: 0.7398 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "Epoch 6/20\n",
      "1049/1049 [==============================] - 5s 5ms/step - loss: 0.5434 - accuracy: 0.7398 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "Epoch 7/20\n",
      "1049/1049 [==============================] - 5s 5ms/step - loss: 0.5188 - accuracy: 0.7398 - precision_35: 0.0000e+00 - recall_35: 0.0000e+00\n",
      "Epoch 8/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.4867 - accuracy: 0.7417 - precision_35: 0.7500 - recall_35: 0.0110\n",
      "Epoch 9/20\n",
      "1049/1049 [==============================] - 6s 5ms/step - loss: 0.4466 - accuracy: 0.7712 - precision_35: 0.7143 - recall_35: 0.2015\n",
      "Epoch 10/20\n",
      "1049/1049 [==============================] - 6s 6ms/step - loss: 0.4129 - accuracy: 0.7836 - precision_35: 0.6949 - recall_35: 0.3004\n",
      "Epoch 11/20\n",
      "1049/1049 [==============================] - 5s 5ms/step - loss: 0.3871 - accuracy: 0.8208 - precision_35: 0.6889 - recall_35: 0.5678\n",
      "Epoch 12/20\n",
      "1049/1049 [==============================] - 5s 5ms/step - loss: 0.3646 - accuracy: 0.8322 - precision_35: 0.7321 - recall_35: 0.5604\n",
      "Epoch 13/20\n",
      "1049/1049 [==============================] - 5s 5ms/step - loss: 0.3437 - accuracy: 0.8351 - precision_35: 0.7358 - recall_35: 0.5714\n",
      "Epoch 14/20\n",
      "1049/1049 [==============================] - 5s 5ms/step - loss: 0.3281 - accuracy: 0.8532 - precision_35: 0.7315 - recall_35: 0.6886\n",
      "Epoch 15/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.3052 - accuracy: 0.8656 - precision_35: 0.7773 - recall_35: 0.6777\n",
      "Epoch 16/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.2770 - accuracy: 0.8856 - precision_35: 0.7823 - recall_35: 0.7766\n",
      "Epoch 17/20\n",
      "1049/1049 [==============================] - 5s 5ms/step - loss: 0.2569 - accuracy: 0.8970 - precision_35: 0.7957 - recall_35: 0.8132\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049/1049 [==============================] - 5s 5ms/step - loss: 0.2359 - accuracy: 0.9028 - precision_35: 0.8132 - recall_35: 0.8132\n",
      "Epoch 19/20\n",
      "1049/1049 [==============================] - 5s 5ms/step - loss: 0.2158 - accuracy: 0.9142 - precision_35: 0.8327 - recall_35: 0.8388\n",
      "Epoch 20/20\n",
      "1049/1049 [==============================] - 5s 5ms/step - loss: 0.1981 - accuracy: 0.9237 - precision_35: 0.8410 - recall_35: 0.8718\n",
      "262/262 [==============================] - 2s 9ms/step\n",
      "loss:  0.5448283104951145\n",
      "accuracy:  0.8015267252922058\n",
      "precision:  0.7407407164573669\n",
      "recall:  0.7692307829856873\n",
      "f1-score:  0.7547169751482694\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_41 (Embedding)     (None, 50, 32)            64000     \n",
      "_________________________________________________________________\n",
      "gru_36 (GRU)                 (None, 50, 16)            2352      \n",
      "_________________________________________________________________\n",
      "seq_self_attention_35 (SeqSe (None, 50, 16)            1089      \n",
      "_________________________________________________________________\n",
      "flatten_40 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 801       \n",
      "=================================================================\n",
      "Total params: 68,242\n",
      "Trainable params: 68,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test set from  1049  to  1310\n",
      "Epoch 1/20\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 0.6839 - accuracy: 0.6730 - precision_36: 0.2561 - recall_36: 0.0693\n",
      "Epoch 2/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.6512 - accuracy: 0.7112 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "Epoch 3/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.6144 - accuracy: 0.7112 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "Epoch 4/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.5947 - accuracy: 0.7112 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "Epoch 5/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.5702 - accuracy: 0.7112 - precision_36: 0.0000e+00 - recall_36: 0.0000e+00\n",
      "Epoch 6/20\n",
      "1049/1049 [==============================] - 5s 5ms/step - loss: 0.5365 - accuracy: 0.7121 - precision_36: 1.0000 - recall_36: 0.0033    - ETA: 4s - loss: 0.5475 - accuracy: 0.7156 - precision_36: 0.0000e+00 \n",
      "Epoch 7/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.4930 - accuracy: 0.7436 - precision_36: 0.8864 - recall_36: 0.1287\n",
      "Epoch 8/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.4464 - accuracy: 0.7798 - precision_36: 0.7951 - recall_36: 0.3201\n",
      "Epoch 9/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.4058 - accuracy: 0.8008 - precision_36: 0.7350 - recall_36: 0.4851\n",
      "Epoch 10/20\n",
      "1049/1049 [==============================] - 4s 4ms/step - loss: 0.3806 - accuracy: 0.8217 - precision_36: 0.7397 - recall_36: 0.5908\n",
      "Epoch 11/20\n",
      "1049/1049 [==============================] - 5s 5ms/step - loss: 0.3539 - accuracy: 0.8322 - precision_36: 0.7452 - recall_36: 0.6370A: 1s - loss: 0.3554 - accuracy: 0.8324 - precision_36: 0.7640 - recall\n",
      "Epoch 12/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.3405 - accuracy: 0.8494 - precision_36: 0.7935 - recall_36: 0.6469\n",
      "Epoch 13/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.3202 - accuracy: 0.8522 - precision_36: 0.7721 - recall_36: 0.6931\n",
      "Epoch 14/20\n",
      "1049/1049 [==============================] - 5s 5ms/step - loss: 0.2999 - accuracy: 0.8751 - precision_36: 0.7867 - recall_36: 0.7789A: 0s - loss: 0.2971 - accuracy: 0.8760 - precision_36: 0.7875 - recall_36: 0.78\n",
      "Epoch 15/20\n",
      "1049/1049 [==============================] - 5s 5ms/step - loss: 0.2758 - accuracy: 0.8770 - precision_36: 0.8152 - recall_36: 0.7426\n",
      "Epoch 16/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.2534 - accuracy: 0.8990 - precision_36: 0.8230 - recall_36: 0.8284\n",
      "Epoch 17/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.2366 - accuracy: 0.8999 - precision_36: 0.8322 - recall_36: 0.8185\n",
      "Epoch 18/20\n",
      "1049/1049 [==============================] - 5s 5ms/step - loss: 0.2189 - accuracy: 0.9123 - precision_36: 0.8392 - recall_36: 0.8614\n",
      "Epoch 19/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.1898 - accuracy: 0.9295 - precision_36: 0.8635 - recall_36: 0.8977\n",
      "Epoch 20/20\n",
      "1049/1049 [==============================] - 5s 4ms/step - loss: 0.1765 - accuracy: 0.9304 - precision_36: 0.8594 - recall_36: 0.9076\n",
      "262/262 [==============================] - 3s 10ms/step\n",
      "loss:  0.998599440086889\n",
      "accuracy:  0.7748091816902161\n",
      "precision:  0.6415094137191772\n",
      "recall:  0.45945945382118225\n",
      "f1-score:  0.5354330599866033\n",
      "total loss:  0.7753881707685009\n",
      "total accuracy:  0.7864366054534913\n",
      "total precision:  0.640187406539917\n",
      "total recall:  0.5321963787078857\n",
      "total f1-score:  0.5750613317422705\n"
     ]
    }
   ],
   "source": [
    "# RNN train with split \n",
    "max_length = 50\n",
    "vocab_size = 2000\n",
    "\n",
    "padded_docs, labels = read_train_Data()\n",
    "# attention will focus on specific words for example comment: auto generated method stub\n",
    "i = 0\n",
    "n_split=5\n",
    "loss = 0\n",
    "accuracy = 0\n",
    "precision = 0\n",
    "recall = 0\n",
    "f1_score = 0\n",
    "for train_index,test_index in KFold(n_split).split(padded_docs):\n",
    "    # define the model\n",
    "    model = RNN(max_length,vocab_size,32)\n",
    "    learning_rate = 0.0002\n",
    "    adam = Adam(\n",
    "        learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False\n",
    "        )\n",
    "    early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    min_delta=0,\n",
    "                                                    patience=5,\n",
    "                                                    verbose=0, mode='auto')\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy',keras.metrics.Precision(),keras.metrics.Recall()])\n",
    "\n",
    "    model,eva = model_fit(model,padded_docs,labels,train_index,test_index, epochs=20)\n",
    "    loss += eva[0]\n",
    "    accuracy += eva[1]\n",
    "    precision += eva[2]\n",
    "    recall += eva[3]\n",
    "    f1_score += (2*eva[3]*eva[2])/(eva[3]+eva[2])\n",
    "\n",
    "print('total loss: ',loss/n_split)\n",
    "print('total accuracy: ',accuracy/n_split)\n",
    "print('total precision: ',precision/n_split)\n",
    "print('total recall: ',recall/n_split)\n",
    "print('total f1-score: ',f1_score/n_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
